I"b<p><strong>Easy Way to build Recommendation System using Content-based
Filtering—In Python–Part-2</strong></p>

<p>In Part-1 we learned a lot of about Collaborative Filtering. In this article we will be taking a look at Content-based Filtering.</p>

<h1 id="what-is-content-based-filtering">What is Content-based Filtering?</h1>

<p>Content-based filtering is the one of the other technique that can be used to recommend items to the user. It does it so by recommending items to user based on the “content”, meaning items that the user may have either purchased or used or liked or disliked.<small> <em>Eg: Recommending Movie1 to ‘X ‘user based on the Movie2 and Movie3 that ‘X’ user has viewed or rated before.</em> </small></p>

<h1 id="content-based-filtering-concepts">Content-based Filtering Concepts</h1>

<p>In part-1 we used Euclidean Distance Score to measure similairyt score but this time we are going to do so by using Pearson Corelation method. You can actually use former method to calculate score there’s nothing wrong with it. We are just changing method just to spice a things little bit.</p>

<h2 id="pearson-correlation-score">Pearson Correlation Score</h2>

<p>The correlation coefficient is a measure of how well two sets of data fit on a straight line.
To visualize this method, you can plot the ratings of two of the critics on a chart, as
shown in Figure 1. Movie1 was rated 3 by User1 and 5 by User2,
so it is placed at (3,5) on the chart.</p>

<p><img src="/ajna_blog/assets/images/fig-1.JPG" alt="fig-1" /></p>

<p>You can also see a straight line on the chart. This is called the best-fit line because it
comes as close to all the items on the chart as possible. If the two critics had identical ratings for every movie, this line would be diagonal and would touch every item
in the chart, giving a perfect correlation score of 1. In the case illustrated, the critics
disagree on a few movies, so the correlation score is about 0.4. Figure 2-3 shows an
example of a much higher correlation, one of about 0.75.</p>

<p><img src="/ajna_blog/assets/images/fig-2.JPG" alt="fig-2" /></p>

<h2 id="how-to-calculate-the-score-for-two-users-using-pearson-method">How to calculate the score for two users using pearson method?</h2>

<p>Let X be the user1’s rated data and Y be the user2’s rated data then it looks somthing like this</p>

<p><img src="/ajna_blog/assets/images/tablepearson.JPG" alt="Table-1" />
<em>Table-1. Pearson Co-relation Score</em></p>

<p>r gives the similarity score</p>

<h1 id="item-comparison">Item comparison</h1>

<p>In part-1 we compared the users and their similarity, we are going to do same but this time for item. <em>Example: let’s say user1 has rated movie1 and movie2. In a dataset there are rating of movie3,movie4,.. so on. We are going to find how similar the movie1 is with other dataset movie2,movie4,.. and similary for movie2 also same.</em> .</p>

<p>Create a file called <em>contentfilter.py</em> in your pc and add the following code in it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">loadMovieLens</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">'/data/movielens'</span><span class="p">):</span>
    <span class="c1"># Get movie titles
</span>    <span class="n">movies</span><span class="o">=</span><span class="p">{}</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="o">+</span><span class="s">'/u.item'</span><span class="p">):</span>
        <span class="p">(</span><span class="nb">id</span><span class="p">,</span><span class="n">title</span><span class="p">)</span><span class="o">=</span><span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'|'</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="n">movies</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">=</span><span class="n">title</span>
    <span class="c1"># Load data
</span>    <span class="n">prefs</span><span class="o">=</span><span class="p">{}</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="o">+</span><span class="s">'/u.data'</span><span class="p">):</span>
            <span class="p">(</span><span class="n">user</span><span class="p">,</span><span class="n">movieid</span><span class="p">,</span><span class="n">rating</span><span class="p">,</span><span class="n">ts</span><span class="p">)</span><span class="o">=</span><span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span> <span class="n">prefs</span><span class="p">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">user</span><span class="p">,{})</span>
            <span class="n">prefs</span><span class="p">[</span><span class="n">user</span><span class="p">][</span><span class="n">movies</span><span class="p">[</span><span class="n">movieid</span><span class="p">]]</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">rating</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prefs</span>
</code></pre></div></div>

<p>This is the similar to previous code. It loads the movielens dataset and returns as prefs dictionary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Returns the Pearson correlation coefficient for p1 and p2
</span><span class="k">def</span> <span class="nf">sim_pearson</span><span class="p">(</span><span class="n">prefs</span><span class="p">,</span><span class="n">p1</span><span class="p">,</span><span class="n">p2</span><span class="p">):</span> 
    <span class="c1"># Get the list of mutually rated items
</span>    <span class="n">si</span><span class="o">=</span><span class="p">{}</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">prefs</span><span class="p">[</span><span class="n">p1</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">prefs</span><span class="p">[</span><span class="n">p2</span><span class="p">]:</span> <span class="n">si</span><span class="p">[</span><span class="n">item</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
    <span class="c1"># Find the number of elements
</span>    <span class="n">n</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">si</span><span class="p">)</span>
    <span class="c1"># if they are no ratings in common, return 0
</span>    <span class="k">if</span> <span class="n">n</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="mi">0</span>
    <span class="c1"># Add up all the preferences
</span>    
    <span class="n">sum1</span><span class="o">=</span><span class="nb">sum</span><span class="p">([</span><span class="n">prefs</span><span class="p">[</span><span class="n">p1</span><span class="p">][</span><span class="n">it</span><span class="p">]</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">si</span><span class="p">])</span>
    <span class="n">sum2</span><span class="o">=</span><span class="nb">sum</span><span class="p">([</span><span class="n">prefs</span><span class="p">[</span><span class="n">p2</span><span class="p">][</span><span class="n">it</span><span class="p">]</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">si</span><span class="p">])</span>
    <span class="c1"># Sum up the squares
</span>    <span class="n">sum1Sq</span><span class="o">=</span><span class="nb">sum</span><span class="p">([</span><span class="nb">pow</span><span class="p">(</span><span class="n">prefs</span><span class="p">[</span><span class="n">p1</span><span class="p">][</span><span class="n">it</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">si</span><span class="p">])</span>
    <span class="n">sum2Sq</span><span class="o">=</span><span class="nb">sum</span><span class="p">([</span><span class="nb">pow</span><span class="p">(</span><span class="n">prefs</span><span class="p">[</span><span class="n">p2</span><span class="p">][</span><span class="n">it</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">si</span><span class="p">])</span>
    <span class="c1"># Sum up the products
</span>    <span class="n">pSum</span><span class="o">=</span><span class="nb">sum</span><span class="p">([</span><span class="n">prefs</span><span class="p">[</span><span class="n">p1</span><span class="p">][</span><span class="n">it</span><span class="p">]</span><span class="o">*</span><span class="n">prefs</span><span class="p">[</span><span class="n">p2</span><span class="p">][</span><span class="n">it</span><span class="p">]</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">si</span><span class="p">])</span>
    <span class="c1"># Calculate Pearson score
</span>    <span class="n">num</span><span class="o">=</span><span class="n">pSum</span><span class="o">-</span><span class="p">(</span><span class="n">sum1</span><span class="o">*</span><span class="n">sum2</span><span class="o">/</span><span class="n">n</span><span class="p">)</span>
    <span class="n">den</span><span class="o">=</span><span class="n">sqrt</span><span class="p">((</span><span class="n">sum1Sq</span><span class="o">-</span><span class="nb">pow</span><span class="p">(</span><span class="n">sum1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">sum2Sq</span><span class="o">-</span><span class="nb">pow</span><span class="p">(</span><span class="n">sum2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">den</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="mi">0</span>
    <span class="n">r</span><span class="o">=</span><span class="n">num</span><span class="o">/</span><span class="n">den</span>
    <span class="k">return</span> <span class="n">r</span>
</code></pre></div></div>

<p>Above function calculates the <em>r</em> which is a similarity score of the items. Now we have similarity score and dataset we are ready to make a recommendation but before that let’s add some code.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">transformPrefs</span><span class="p">(</span><span class="n">prefs</span><span class="p">):</span>
    <span class="n">result</span><span class="o">=</span><span class="p">{}</span>
    <span class="k">for</span> <span class="n">person</span> <span class="ow">in</span> <span class="n">prefs</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">prefs</span><span class="p">[</span><span class="n">person</span><span class="p">]:</span>
            <span class="n">result</span><span class="p">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">item</span><span class="p">,{})</span>
            <span class="c1"># Flip item and person
</span>            <span class="n">result</span><span class="p">[</span><span class="n">item</span><span class="p">][</span><span class="n">person</span><span class="p">]</span><span class="o">=</span><span class="n">prefs</span><span class="p">[</span><span class="n">person</span><span class="p">][</span><span class="n">item</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<p>We have a dataset in the form of <em>{‘user1’:{movie1:’4.5’,movie2:’3’}}</em> with transformPrefs() function we are converting it to be item-centric rather than user-centric. <em>Eg: {‘movie1’:{user1:’4.5’},’movie2’:{‘user1:’3’}} by transforming it now we can calculate similaity of items</em></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">topMatches</span><span class="p">(</span><span class="n">prefs</span><span class="p">,</span><span class="n">person</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">similarity</span><span class="o">=</span><span class="n">sim_pearson</span><span class="p">):</span>
    <span class="n">scores</span><span class="o">=</span><span class="p">[(</span><span class="n">similarity</span><span class="p">(</span><span class="n">prefs</span><span class="p">,</span><span class="n">person</span><span class="p">,</span><span class="n">other</span><span class="p">),</span><span class="n">other</span><span class="p">)</span> <span class="k">for</span> <span class="n">other</span> <span class="ow">in</span> <span class="n">prefs</span> <span class="k">if</span> <span class="n">other</span><span class="o">!=</span><span class="n">person</span><span class="p">]</span>
    <span class="c1"># print(scores)
</span>    <span class="c1"># Sort the list so the highest scores appear at the top
</span>    <span class="n">scores</span><span class="p">.</span><span class="n">sort</span><span class="p">()</span>
    <span class="n">scores</span><span class="p">.</span><span class="n">reverse</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]</span>
</code></pre></div></div>

<p>It’s the same function as before in part-1 which return highest matching item in reverse order</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">calculateSimilarItems</span><span class="p">(</span><span class="n">prefs</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Create a dictionary of items showing which other items they
</span>    <span class="c1"># are most similar to.
</span>    <span class="n">result</span><span class="o">=</span><span class="p">{}</span>
    <span class="c1"># Invert the preference matrix to be item-centric
</span>    <span class="c1"># print(prefs)
</span>    <span class="c1"># print('----------------------------------')
</span>    <span class="n">itemPrefs</span><span class="o">=</span><span class="n">transformPrefs</span><span class="p">(</span><span class="n">prefs</span><span class="p">)</span>
    <span class="c1"># print(itemPrefs)
</span>    <span class="n">c</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">itemPrefs</span><span class="p">:</span>
        <span class="c1"># Status updates for large datasets
</span>        <span class="n">c</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">c</span><span class="o">%</span><span class="mi">100</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="k">pass</span>
        <span class="c1"># Find the most similar items to this one
</span>        <span class="n">scores</span><span class="o">=</span><span class="n">topMatches</span><span class="p">(</span><span class="n">itemPrefs</span><span class="p">,</span><span class="n">item</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span><span class="n">similarity</span><span class="o">=</span><span class="n">sim_distance</span><span class="p">)</span>
        <span class="n">result</span><span class="p">[</span><span class="n">item</span><span class="p">]</span><span class="o">=</span><span class="n">scores</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<p>Now we calculate similarity for each items using calculateSimilarItems() function. The last part is getting recommendations</p>

<h1 id="content-based-recommendations-theory">Content-based Recommendations Theory</h1>

<p>Let’s look at how things have changed in more layman terms. We will create a table to make it more understandable. Table-1 shows the process of finding recommendation using Content-based Filtering approch. Unlike part-1 there was user involved in the recommendation and instead there is a grid of movies that a particular user ‘Bobby’ has rated. This is why we have created <em>transformPrefs(prefs)</em>.</p>

<p><img src="/ajna_blog/assets/images/contentbasedtable.JPG" alt="Table-2" />
<em>Table-2. Content-based recommendations for Bobby</em></p>

<p>Column movie and Rating show the movies that that Bobby has seen and rated personally. For every movie that Bobby haven’t seen,there’s a column that shows how similar it is to the movie that he has seen–for example the similarity score between superman and batman is 0.103. The column R.x is the muliplication of rating by similarity–4.0*0.103 = 0.412. And the predicated rating for Batman is 1.378/0.433 = 3.183</p>

<h1 id="content-based-recommendations-practical">Content-based Recommendations Practical</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">getRecommendedContent</span><span class="p">(</span><span class="n">prefs</span><span class="p">,</span><span class="n">itemMatch</span><span class="p">,</span><span class="n">user</span><span class="p">):</span>
    <span class="n">userRatings</span><span class="o">=</span><span class="n">prefs</span><span class="p">[</span><span class="n">user</span><span class="p">]</span>
    <span class="n">scores</span><span class="o">=</span><span class="p">{}</span>
    <span class="n">totalSim</span><span class="o">=</span><span class="p">{}</span>
    <span class="c1"># Loop over items rated by this user
</span>    <span class="k">for</span> <span class="p">(</span><span class="n">item</span><span class="p">,</span><span class="n">rating</span><span class="p">)</span> <span class="ow">in</span> <span class="n">userRatings</span><span class="p">.</span><span class="n">items</span><span class="p">(</span> <span class="p">):</span>
        <span class="c1"># Loop over items similar to this one
</span>        <span class="k">for</span> <span class="p">(</span><span class="n">similarity</span><span class="p">,</span><span class="n">item2</span><span class="p">)</span> <span class="ow">in</span> <span class="n">itemMatch</span><span class="p">[</span><span class="n">item</span><span class="p">]:</span>
            <span class="c1"># Ignore if this user has already rated this item
</span>            <span class="k">if</span> <span class="n">item2</span> <span class="ow">in</span> <span class="n">userRatings</span><span class="p">:</span> <span class="k">continue</span>
            <span class="c1"># Weighted sum of rating times similarity
</span>            <span class="n">scores</span><span class="p">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">item2</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">scores</span><span class="p">[</span><span class="n">item2</span><span class="p">]</span><span class="o">+=</span><span class="n">similarity</span><span class="o">*</span><span class="n">rating</span>
            <span class="c1"># Sum of all the similarities
</span>            <span class="n">totalSim</span><span class="p">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">item2</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">totalSim</span><span class="p">[</span><span class="n">item2</span><span class="p">]</span><span class="o">+=</span><span class="n">similarity</span>
    <span class="c1"># Divide each total score by total weighting to get an average
</span>    <span class="n">rankings</span><span class="o">=</span><span class="p">[(</span><span class="n">score</span><span class="o">/</span><span class="n">totalSim</span><span class="p">[</span><span class="n">item</span><span class="p">],</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span><span class="p">,</span><span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">.</span><span class="n">items</span><span class="p">(</span> <span class="p">)]</span>
    <span class="c1"># Return the rankings from highest to lowest
</span>    <span class="n">rankings</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span> <span class="p">)</span>
    <span class="n">rankings</span><span class="p">.</span><span class="n">reverse</span><span class="p">(</span> <span class="p">)</span>
    <span class="k">return</span> <span class="n">rankings</span>
</code></pre></div></div>

<p>This is the python form of the Table-2 which the returns dictionary of recommended movie. now let’s load the dataset and start calling the function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prefs</span><span class="o">=</span><span class="n">loadMovieLens</span><span class="p">()</span>
<span class="n">items</span><span class="o">=</span><span class="n">calculateSimilarItems</span><span class="p">(</span><span class="n">prefs</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Recommended movie for "</span><span class="p">,</span><span class="n">getRecommendedItems</span><span class="p">(</span><span class="n">prefs</span><span class="p">,</span><span class="n">items</span><span class="p">,</span><span class="s">'87'</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">30</span><span class="p">])</span> 
</code></pre></div></div>

<p>Here we are loading the movies and store it in prefs the we are calcualting similar items and storing it in items the finally getting recommentionf in last line</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python3 contentfilter.py
<span class="o">[(</span>5.0, <span class="s2">"What's Eating Gilbert Grape (1993)"</span><span class="o">)</span>, <span class="o">(</span>5.0, <span class="s1">'Vertigo (1958)'</span><span class="o">)</span>,
 <span class="o">(</span>5.0, <span class="s1">'Usual Suspects, The (1995)'</span><span class="o">)</span>, <span class="o">(</span>5.0, <span class="s1">'Toy Story (1995)'</span><span class="o">)</span>,etc...]

</code></pre></div></div>
<p>There you go we have created a Content-based filtering.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Content-based filtering is significantly faster than user-based when getting a list of recommendations for a large dataset, but it does have the additional overhead of maintaining the item similarity table. Also, there is a difference in accuracy that depends
on how “sparse” the dataset is. Time and again we only need to calculate the similarity score of the items and then use it while making recommention. This is way it is useful in large dataset whose value rarely changes. User-based filtering is simpler to implement and doesn’t have the
extra steps, so it is often more appropriate with smaller in-memory datasets that
change very frequently</p>

:ET